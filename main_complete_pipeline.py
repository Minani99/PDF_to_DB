"""
ì™„ì „í•œ PDF â†’ JSON â†’ ì •ê·œí™” â†’ DB íŒŒì´í”„ë¼ì¸
ì •ë¶€/ê³µê³µê¸°ê´€ í‘œì¤€ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ
"""
import os
import sys
import json
from pathlib import Path
import logging
from datetime import datetime
from typing import Dict, Any, Optional

# ëª¨ë“ˆ ì„í¬íŠ¸
from extract_pdf_to_json import extract_pdf_to_json
from normalize_government_standard import GovernmentStandardNormalizer
from load_government_standard_db import GovernmentStandardDBLoader
from config import MYSQL_CONFIG

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class CompletePipeline:
    """PDFë¶€í„° DBê¹Œì§€ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, pdf_path: str = None, skip_db: bool = False):
        """
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìƒ˜í”Œ ë°ì´í„°)
            skip_db: DB ì ì¬ ê±´ë„ˆë›°ê¸° (í…ŒìŠ¤íŠ¸ìš©)
        """
        self.pdf_path = Path(pdf_path) if pdf_path else None
        self.skip_db = skip_db
        
        # ë””ë ‰í† ë¦¬ ì„¤ì •
        self.input_dir = Path("input")
        self.json_dir = Path("output")
        self.csv_dir = Path("normalized_output_government")
        self.viz_dir = Path("visualization_government")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        for dir_path in [self.input_dir, self.json_dir, self.csv_dir, self.viz_dir]:
            dir_path.mkdir(exist_ok=True)
        
        # íŒŒì´í”„ë¼ì¸ í†µê³„
        self.stats = {
            'start_time': datetime.now(),
            'pdf_extracted': False,
            'json_created': False,
            'normalized': False,
            'db_loaded': False,
            'total_records': 0,
            'errors': []
        }
    
    def run(self) -> bool:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info("="*80)
        logger.info("ğŸš€ ì™„ì „í•œ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info("="*80)
        
        try:
            # 1ë‹¨ê³„: PDF â†’ JSON
            json_data = self._extract_pdf()
            if not json_data:
                return False
            
            # 2ë‹¨ê³„: JSON â†’ ì •ê·œí™”
            normalized = self._normalize_data(json_data)
            if not normalized:
                return False
            
            # 3ë‹¨ê³„: ì •ê·œí™” ë°ì´í„° â†’ DB (ì˜µì…˜)
            if not self.skip_db:
                db_loaded = self._load_to_database()
                if not db_loaded:
                    logger.warning("DB ì ì¬ ì‹¤íŒ¨í–ˆì§€ë§Œ ì •ê·œí™”ëŠ” ì™„ë£Œë¨")
            
            # 4ë‹¨ê³„: ê²€ì¦ ë° ë³´ê³ ì„œ
            self._generate_report()
            
            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            self.stats['errors'].append(str(e))
            return False
        
        finally:
            self._print_summary()
    
    def _extract_pdf(self) -> Optional[Dict[str, Any]]:
        """1ë‹¨ê³„: PDF ì¶”ì¶œ"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“„ 1ë‹¨ê³„: PDF â†’ JSON ë³€í™˜")
        logger.info("="*60)
        
        try:
            # PDF ì¶”ì¶œ
            if self.pdf_path and self.pdf_path.exists():
                logger.info(f"PDF íŒŒì¼: {self.pdf_path}")
                json_data = extract_pdf_to_json(str(self.pdf_path), str(self.json_dir))
            else:
                logger.info("ìƒ˜í”Œ ë°ì´í„° ëª¨ë“œ ì‚¬ìš©")
                json_data = extract_pdf_to_json(None, str(self.json_dir))
            
            if json_data:
                self.stats['pdf_extracted'] = True
                self.stats['json_created'] = True
                
                # JSON íŒŒì¼ ì €ì¥
                json_file = self.json_dir / "extracted_data.json"
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(json_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"âœ… JSON ìƒì„±: {json_file}")
                logger.info(f"   - í˜ì´ì§€: {len(json_data.get('pages', []))}ê°œ")
                
                # í…Œì´ë¸” ìˆ˜ ê³„ì‚°
                total_tables = sum(
                    len(page.get('tables', [])) 
                    for page in json_data.get('pages', [])
                )
                logger.info(f"   - í…Œì´ë¸”: {total_tables}ê°œ")
                
                return json_data
                
        except Exception as e:
            logger.error(f"PDF ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            self.stats['errors'].append(f"PDF ì¶”ì¶œ: {str(e)}")
            
        return None
    
    def _normalize_data(self, json_data: Dict[str, Any]) -> bool:
        """2ë‹¨ê³„: ë°ì´í„° ì •ê·œí™”"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ”„ 2ë‹¨ê³„: ë°ì´í„° ì •ê·œí™”")
        logger.info("="*60)
        
        try:
            # JSON íŒŒì¼ ê²½ë¡œ
            json_file = self.json_dir / "extracted_data.json"
            
            # ì •ê·œí™” ì‹¤í–‰
            normalizer = GovernmentStandardNormalizer(
                str(json_file),
                str(self.csv_dir)
            )
            
            # ì •ê·œí™” ì²˜ë¦¬
            success = normalizer.normalize(json_data)
            
            if success:
                # CSV ì €ì¥
                normalizer.save_to_csv()
                
                # í†µê³„ ì¶œë ¥
                normalizer.print_statistics()
                
                # ê²€ì¦
                validation = normalizer.validate_data()
                
                self.stats['normalized'] = True
                self.stats['total_records'] = sum(
                    len(records) for records in normalizer.data.values()
                    if isinstance(records, list)
                )
                
                logger.info(f"âœ… ì •ê·œí™” ì™„ë£Œ:")
                logger.info(f"   - ë‚´ì—­ì‚¬ì—…: {len(normalizer.data.get('sub_projects', []))}ê°œ")
                logger.info(f"   - ì¼ì •: {len(normalizer.data.get('normalized_schedules', []))}ê±´")
                logger.info(f"   - ì„±ê³¼: {len(normalizer.data.get('normalized_performances', []))}ê±´")
                logger.info(f"   - ì˜ˆì‚°: {len(normalizer.data.get('normalized_budgets', []))}ê±´")
                
                if validation.get('issues'):
                    logger.warning(f"   âš ï¸ ê²€ì¦ ì´ìŠˆ: {len(validation['issues'])}ê°œ")
                else:
                    logger.info(f"   âœ“ ë°ì´í„° ê²€ì¦ í†µê³¼")
                
                return True
                
        except Exception as e:
            logger.error(f"ì •ê·œí™” ì‹¤íŒ¨: {e}")
            self.stats['errors'].append(f"ì •ê·œí™”: {str(e)}")
            
        return False
    
    def _load_to_database(self) -> bool:
        """3ë‹¨ê³„: DB ì ì¬"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ’¾ 3ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì ì¬")
        logger.info("="*60)
        
        try:
            # DB ì„¤ì •
            db_config = MYSQL_CONFIG.copy()
            db_config['database'] = 'government_standard'
            
            # ì ì¬ ì‹¤í–‰
            loader = GovernmentStandardDBLoader(db_config, str(self.csv_dir))
            
            # ì—°ê²°
            loader.connect()
            
            # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
            loader.drop_existing_tables()
            
            # í…Œì´ë¸” ìƒì„±
            loader.create_tables()
            
            # ë°ì´í„° ì ì¬
            loader.load_all_tables()
            
            # ê²€ì¦
            verification = loader.verify_data_integrity()
            
            loader.close()
            
            self.stats['db_loaded'] = True
            
            logger.info(f"âœ… DB ì ì¬ ì™„ë£Œ:")
            logger.info(f"   - í…Œì´ë¸”: {loader.load_stats['tables_created']}ê°œ")
            logger.info(f"   - ë ˆì½”ë“œ: {loader.load_stats['total_records']:,}ê±´")
            
            if verification.get('orphan_records'):
                logger.warning(f"   âš ï¸ ê³ ì•„ ë ˆì½”ë“œ: {len(verification['orphan_records'])}ê°œ")
            else:
                logger.info(f"   âœ“ ë¬´ê²°ì„± ê²€ì¦ í†µê³¼")
            
            return True
            
        except Exception as e:
            logger.error(f"DB ì ì¬ ì‹¤íŒ¨: {e}")
            self.stats['errors'].append(f"DB ì ì¬: {str(e)}")
            
        return False
    
    def _generate_report(self):
        """ë³´ê³ ì„œ ìƒì„±"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š 4ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„±")
        logger.info("="*60)
        
        report = []
        report.append("="*80)
        report.append("ğŸ“Š ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë³´ê³ ì„œ")
        report.append("="*80)
        report.append(f"ì‹¤í–‰ ì‹œê°„: {self.stats['start_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ì†Œìš” ì‹œê°„: {(datetime.now() - self.stats['start_time']).total_seconds():.1f}ì´ˆ")
        report.append("")
        
        # ë‹¨ê³„ë³„ ìƒíƒœ
        report.append("ğŸ“‹ ì²˜ë¦¬ ë‹¨ê³„:")
        report.append(f"  1. PDF ì¶”ì¶œ: {'âœ…' if self.stats['pdf_extracted'] else 'âŒ'}")
        report.append(f"  2. JSON ìƒì„±: {'âœ…' if self.stats['json_created'] else 'âŒ'}")
        report.append(f"  3. ì •ê·œí™”: {'âœ…' if self.stats['normalized'] else 'âŒ'}")
        report.append(f"  4. DB ì ì¬: {'âœ…' if self.stats['db_loaded'] else 'â­ï¸ ê±´ë„ˆëœ€'}")
        report.append("")
        
        # ë°ì´í„° í†µê³„
        report.append("ğŸ“Š ë°ì´í„° í†µê³„:")
        report.append(f"  ì´ ë ˆì½”ë“œ: {self.stats['total_records']:,}ê±´")
        report.append("")
        
        # ì˜¤ë¥˜
        if self.stats['errors']:
            report.append("âŒ ì˜¤ë¥˜:")
            for error in self.stats['errors']:
                report.append(f"  - {error}")
            report.append("")
        
        # ìƒì„±ëœ íŒŒì¼
        report.append("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
        report.append(f"  - JSON: output/extracted_data.json")
        report.append(f"  - CSV: normalized_output_government/*.csv")
        if self.stats['db_loaded']:
            report.append(f"  - DB: government_standard ë°ì´í„°ë² ì´ìŠ¤")
        report.append("")
        
        report.append("="*80)
        
        # ë³´ê³ ì„œ ì €ì¥
        report_text = "\n".join(report)
        report_file = self.viz_dir / f"pipeline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        logger.info(f"âœ… ë³´ê³ ì„œ ìƒì„±: {report_file}")
    
    def _print_summary(self):
        """ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìš”ì•½")
        print("="*80)
        
        # ì„±ê³µ/ì‹¤íŒ¨ ìƒíƒœ
        success_count = sum([
            self.stats['pdf_extracted'],
            self.stats['json_created'],
            self.stats['normalized'],
            self.stats['db_loaded']
        ])
        
        total_steps = 4 if not self.skip_db else 3
        
        print(f"âœ… ì„±ê³µ: {success_count}/{total_steps} ë‹¨ê³„")
        print(f"ğŸ“Š ì²˜ë¦¬ ë ˆì½”ë“œ: {self.stats['total_records']:,}ê±´")
        print(f"â±ï¸ ì†Œìš” ì‹œê°„: {(datetime.now() - self.stats['start_time']).total_seconds():.1f}ì´ˆ")
        
        if self.stats['errors']:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {len(self.stats['errors'])}ê°œ")
        
        print("="*80)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="PDF â†’ JSON â†’ ì •ê·œí™” â†’ DB ì™„ì „í•œ íŒŒì´í”„ë¼ì¸"
    )
    parser.add_argument(
        'pdf_file',
        nargs='?',
        help='ì²˜ë¦¬í•  PDF íŒŒì¼ ê²½ë¡œ (ìƒëµí•˜ë©´ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©)'
    )
    parser.add_argument(
        '--skip-db',
        action='store_true',
        help='DB ì ì¬ ê±´ë„ˆë›°ê¸° (í…ŒìŠ¤íŠ¸ìš©)'
    )
    
    args = parser.parse_args()
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = CompletePipeline(
        pdf_path=args.pdf_file,
        skip_db=args.skip_db
    )
    
    success = pipeline.run()
    
    if success:
        print("\nâœ… íŒŒì´í”„ë¼ì¸ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
        print("ğŸ“ ê²°ê³¼ í™•ì¸:")
        print("  - JSON: output/extracted_data.json")
        print("  - CSV: normalized_output_government/*.csv")
        if not args.skip_db:
            print("  - DB: government_standard ë°ì´í„°ë² ì´ìŠ¤")
    else:
        print("\nâš ï¸ íŒŒì´í”„ë¼ì¸ ì¼ë¶€ ì‹¤íŒ¨. ë³´ê³ ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())