"""
ê°œì„ ëœ MySQL ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ ëª¨ë“ˆ
ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ íŠ¸ëœì­ì…˜ ê´€ë¦¬ ë° ì„±ëŠ¥ ìµœì í™” êµ¬í˜„
"""
import csv
import json
import mysql.connector
from mysql.connector import Error
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging
from contextlib import contextmanager
from config import MYSQL_CONFIG

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ImprovedDBLoader:
    """ê°œì„ ëœ ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ í´ë˜ìŠ¤"""
    
    # í…Œì´ë¸” ìƒì„± ìˆœì„œ (ì™¸ë˜í‚¤ ì¢…ì†ì„± ê³ ë ¤)
    TABLE_ORDER = [
        "departments",
        "main_projects", 
        "sub_projects",
        "categories",
        "project_category_data",
        "project_overviews",
        "budgets",
        "performance_indicators",
        "project_schedules",
        "document_metadata",
        "raw_page_data",
        "audit_logs"
    ]
    
    # ë°°ì¹˜ í¬ê¸° ì„¤ì •
    BATCH_SIZE = 100
    
    def __init__(self, csv_dir: str):
        self.csv_dir = Path(csv_dir)
        self.connection = None
        self.cursor = None
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            "tables_created": 0,
            "records_inserted": 0,
            "batch_count": 0,
            "errors": []
        }
    
    @contextmanager
    def db_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        try:
            self.connection = mysql.connector.connect(
                host=MYSQL_CONFIG.get("host", "localhost"),
                user=MYSQL_CONFIG.get("user", "root"),
                password=MYSQL_CONFIG["password"],
                database=MYSQL_CONFIG.get("database", "convert_pdf"),
                charset='utf8mb4',
                use_unicode=True,
                autocommit=False,  # íŠ¸ëœì­ì…˜ ìˆ˜ë™ ê´€ë¦¬
                connection_timeout=30
            )
            self.cursor = self.connection.cursor(dictionary=True)
            
            # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            self.cursor.execute("SET FOREIGN_KEY_CHECKS = 0")
            self.cursor.execute("SET UNIQUE_CHECKS = 0")
            self.cursor.execute("SET AUTOCOMMIT = 0")
            
            yield
            
            # ì„¤ì • ë³µì›
            self.cursor.execute("SET FOREIGN_KEY_CHECKS = 1")
            self.cursor.execute("SET UNIQUE_CHECKS = 1")
            self.cursor.execute("SET AUTOCOMMIT = 1")
            
        except Error as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
        finally:
            if self.cursor:
                self.cursor.close()
            if self.connection:
                self.connection.close()
    
    def create_tables(self):
        """í…Œì´ë¸” ìƒì„±"""
        try:
            # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ (ì—­ìˆœ)
            for table_name in reversed(self.TABLE_ORDER):
                self.cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
            
            # í…Œì´ë¸” ìƒì„± SQL
            create_sqls = self._get_create_table_sqls()
            
            for sql in create_sqls:
                self.cursor.execute(sql)
                self.stats["tables_created"] += 1
            
            self.connection.commit()
            logger.info(f"âœ… {self.stats['tables_created']}ê°œ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
        except Error as e:
            self.connection.rollback()
            logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _get_create_table_sqls(self) -> List[str]:
        """í…Œì´ë¸” ìƒì„± SQL ë°˜í™˜"""
        return [
            # ë¶€ì²˜
            """
            CREATE TABLE departments (
                id INT PRIMARY KEY,
                code VARCHAR(50) UNIQUE NOT NULL,
                name VARCHAR(200) NOT NULL,
                description TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_code (code),
                INDEX idx_name (name)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ì„¸ë¶€ì‚¬ì—…
            """
            CREATE TABLE main_projects (
                id INT PRIMARY KEY,
                department_id INT NOT NULL,
                code VARCHAR(100) UNIQUE,
                name VARCHAR(500) NOT NULL,
                fiscal_year INT NOT NULL,
                status VARCHAR(20) DEFAULT 'active',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                FOREIGN KEY (department_id) REFERENCES departments(id) ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_dept_year (department_id, fiscal_year),
                INDEX idx_name (name),
                INDEX idx_fiscal_year (fiscal_year)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ë‚´ì—­ì‚¬ì—…
            """
            CREATE TABLE sub_projects (
                id INT PRIMARY KEY,
                main_project_id INT NOT NULL,
                code VARCHAR(100),
                name VARCHAR(500) NOT NULL,
                project_type VARCHAR(100),
                priority INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                FOREIGN KEY (main_project_id) REFERENCES main_projects(id) ON DELETE CASCADE ON UPDATE CASCADE,
                UNIQUE KEY uk_main_sub (main_project_id, code),
                INDEX idx_main_project (main_project_id),
                INDEX idx_name (name),
                INDEX idx_type (project_type)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ì¹´í…Œê³ ë¦¬
            """
            CREATE TABLE categories (
                id INT PRIMARY KEY,
                code VARCHAR(50) UNIQUE NOT NULL,
                name VARCHAR(200) NOT NULL,
                parent_id INT,
                level INT DEFAULT 1,
                display_order INT DEFAULT 0,
                is_active BOOLEAN DEFAULT TRUE,
                FOREIGN KEY (parent_id) REFERENCES categories(id) ON DELETE SET NULL ON UPDATE CASCADE,
                INDEX idx_parent (parent_id),
                INDEX idx_level (level),
                INDEX idx_code (code)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # í”„ë¡œì íŠ¸ ì¹´í…Œê³ ë¦¬ ë°ì´í„° (EAV)
            """
            CREATE TABLE project_category_data (
                id BIGINT PRIMARY KEY,
                sub_project_id INT NOT NULL,
                category_id INT NOT NULL,
                attribute_key VARCHAR(100) NOT NULL,
                attribute_value TEXT,
                data_type VARCHAR(50),
                sequence_order INT DEFAULT 0,
                version INT DEFAULT 1,
                is_current BOOLEAN DEFAULT TRUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) ON DELETE CASCADE ON UPDATE CASCADE,
                FOREIGN KEY (category_id) REFERENCES categories(id) ON UPDATE CASCADE,
                INDEX idx_project_category (sub_project_id, category_id),
                INDEX idx_key (attribute_key),
                INDEX idx_current (is_current),
                INDEX idx_version (version)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ì‚¬ì—…ê°œìš”
            """
            CREATE TABLE project_overviews (
                id INT PRIMARY KEY,
                sub_project_id INT UNIQUE NOT NULL,
                managing_org VARCHAR(500),
                supervising_org VARCHAR(500),
                research_period VARCHAR(200),
                total_budget DECIMAL(20, 2),
                objectives TEXT,
                content TEXT,
                representative_field VARCHAR(500),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) ON DELETE CASCADE ON UPDATE CASCADE,
                FULLTEXT INDEX ft_objectives (objectives),
                FULLTEXT INDEX ft_content (content)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ì˜ˆì‚°
            """
            CREATE TABLE budgets (
                id BIGINT PRIMARY KEY,
                sub_project_id INT NOT NULL,
                fiscal_year INT NOT NULL,
                budget_type VARCHAR(50),
                planned_amount DECIMAL(20, 2),
                executed_amount DECIMAL(20, 2),
                execution_rate DECIMAL(5, 2),
                currency VARCHAR(10) DEFAULT 'KRW',
                remarks TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_project_year (sub_project_id, fiscal_year),
                INDEX idx_year (fiscal_year),
                INDEX idx_type (budget_type)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ì„±ê³¼ì§€í‘œ
            """
            CREATE TABLE performance_indicators (
                id BIGINT PRIMARY KEY,
                sub_project_id INT NOT NULL,
                indicator_type VARCHAR(100),
                indicator_name VARCHAR(500),
                target_value DECIMAL(20, 2),
                achieved_value DECIMAL(20, 2),
                achievement_rate DECIMAL(5, 2),
                unit VARCHAR(50),
                measurement_year INT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_project_type (sub_project_id, indicator_type),
                INDEX idx_year (measurement_year),
                INDEX idx_type (indicator_type)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ì¼ì •
            """
            CREATE TABLE project_schedules (
                id BIGINT PRIMARY KEY,
                sub_project_id INT NOT NULL,
                phase VARCHAR(100),
                task_name VARCHAR(500),
                start_date DATE,
                end_date DATE,
                status VARCHAR(50),
                description TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_project_phase (sub_project_id, phase),
                INDEX idx_dates (start_date, end_date),
                INDEX idx_status (status)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
            """
            CREATE TABLE document_metadata (
                id INT PRIMARY KEY,
                file_name VARCHAR(500) NOT NULL,
                file_path VARCHAR(1000),
                file_size BIGINT,
                page_count INT,
                extraction_date TIMESTAMP,
                processing_status VARCHAR(50),
                error_message TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_status (processing_status),
                INDEX idx_file_name (file_name)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ì›ë³¸ í˜ì´ì§€ ë°ì´í„°
            """
            CREATE TABLE raw_page_data (
                id BIGINT PRIMARY KEY,
                document_id INT NOT NULL,
                page_number INT NOT NULL,
                raw_text LONGTEXT,
                extracted_tables JSON,
                processing_notes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (document_id) REFERENCES document_metadata(id) ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_doc_page (document_id, page_number),
                FULLTEXT INDEX ft_raw_text (raw_text)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """,
            
            # ê°ì‚¬ ë¡œê·¸
            """
            CREATE TABLE audit_logs (
                id BIGINT PRIMARY KEY,
                table_name VARCHAR(100) NOT NULL,
                record_id BIGINT NOT NULL,
                action VARCHAR(50) NOT NULL,
                old_value JSON,
                new_value JSON,
                changed_by VARCHAR(100),
                changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_table_record (table_name, record_id),
                INDEX idx_changed_at (changed_at),
                INDEX idx_action (action)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
            """
        ]
    
    def load_csv_data(self):
        """CSV ë°ì´í„° ì ì¬"""
        try:
            for table_name in self.TABLE_ORDER:
                csv_path = self.csv_dir / f"{table_name}.csv"
                
                if not csv_path.exists():
                    logger.warning(f"âš ï¸ CSV íŒŒì¼ ì—†ìŒ: {csv_path}")
                    continue
                
                self._load_single_csv(table_name, csv_path)
            
            self.connection.commit()
            logger.info(f"âœ… ì´ {self.stats['records_inserted']}ê°œ ë ˆì½”ë“œ ì ì¬ ì™„ë£Œ")
            
        except Error as e:
            self.connection.rollback()
            logger.error(f"ë°ì´í„° ì ì¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _load_single_csv(self, table_name: str, csv_path: Path):
        """ë‹¨ì¼ CSV íŒŒì¼ ì ì¬"""
        try:
            with open(csv_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
            
            if not rows:
                logger.warning(f"âš ï¸ ë¹ˆ CSV íŒŒì¼: {table_name}")
                return
            
            # ë°°ì¹˜ ì²˜ë¦¬
            batch_count = 0
            for i in range(0, len(rows), self.BATCH_SIZE):
                batch = rows[i:i + self.BATCH_SIZE]
                self._insert_batch(table_name, batch)
                batch_count += 1
                self.stats["batch_count"] += 1
                
                # ì§„í–‰ ìƒí™© ë¡œê¹…
                if batch_count % 10 == 0:
                    logger.info(f"  - {table_name}: {i + len(batch)}/{len(rows)} ì²˜ë¦¬ ì¤‘...")
            
            self.stats["records_inserted"] += len(rows)
            logger.info(f"âœ… {table_name}: {len(rows)}ê°œ ë ˆì½”ë“œ ì ì¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"CSV ì ì¬ ì‹¤íŒ¨ ({table_name}): {e}")
            self.stats["errors"].append(f"{table_name}: {str(e)}")
            raise
    
    def _insert_batch(self, table_name: str, batch: List[Dict[str, Any]]):
        """ë°°ì¹˜ INSERT ì‹¤í–‰"""
        if not batch:
            return
        
        # ì»¬ëŸ¼ëª…ê³¼ í”Œë ˆì´ìŠ¤í™€ë” ìƒì„±
        columns = list(batch[0].keys())
        placeholders = ', '.join(['%s'] * len(columns))
        column_names = ', '.join([f"`{col}`" for col in columns])
        
        # INSERT SQL
        sql = f"""
            INSERT INTO {table_name} ({column_names})
            VALUES ({placeholders})
        """
        
        # ë°ì´í„° ì¤€ë¹„
        data = []
        for row in batch:
            values = []
            for col in columns:
                value = row[col]
                
                # NULL ì²˜ë¦¬
                if value == '' or value == 'None':
                    value = None
                # Boolean ì²˜ë¦¬
                elif col in ['is_active', 'is_current'] and value is not None:
                    value = value.lower() in ['true', '1', 'yes']
                # ìˆ«ì ì²˜ë¦¬
                elif col in ['fiscal_year', 'measurement_year', 'page_number', 
                           'level', 'display_order', 'priority', 'version']:
                    value = int(value) if value else None
                elif col in ['total_budget', 'planned_amount', 'executed_amount',
                           'target_value', 'achieved_value', 'execution_rate', 
                           'achievement_rate']:
                    value = float(value) if value else None
                # ë‚ ì§œ ì²˜ë¦¬
                elif col in ['start_date', 'end_date']:
                    if value and value != 'None':
                        try:
                            # YYYY-MM-DD í˜•ì‹ í™•ì¸
                            datetime.strptime(value, '%Y-%m-%d')
                        except:
                            value = None
                # JSON ì²˜ë¦¬
                elif col in ['old_value', 'new_value', 'extracted_tables']:
                    if value and value != 'None':
                        try:
                            # ì´ë¯¸ JSON ë¬¸ìì—´ì¸ì§€ í™•ì¸
                            json.loads(value)
                        except:
                            value = json.dumps(value, ensure_ascii=False)
                    else:
                        value = None
                
                values.append(value)
            
            data.append(tuple(values))
        
        # ë°°ì¹˜ ì‹¤í–‰
        self.cursor.executemany(sql, data)
    
    def verify_data(self):
        """ë°ì´í„° ê²€ì¦"""
        logger.info("\në°ì´í„° ê²€ì¦ ì‹œì‘...")
        
        verification_queries = [
            ("ë¶€ì²˜ë³„ ì„¸ë¶€ì‚¬ì—… ìˆ˜", """
                SELECT d.name AS ë¶€ì²˜ëª…, COUNT(mp.id) AS ì„¸ë¶€ì‚¬ì—…ìˆ˜
                FROM departments d
                LEFT JOIN main_projects mp ON d.id = mp.department_id
                GROUP BY d.id, d.name
            """),
            
            ("ì„¸ë¶€ì‚¬ì—…ë³„ ë‚´ì—­ì‚¬ì—… ìˆ˜", """
                SELECT mp.name AS ì„¸ë¶€ì‚¬ì—…ëª…, COUNT(sp.id) AS ë‚´ì—­ì‚¬ì—…ìˆ˜
                FROM main_projects mp
                LEFT JOIN sub_projects sp ON mp.id = sp.main_project_id
                GROUP BY mp.id, mp.name
                LIMIT 5
            """),
            
            ("ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ìˆ˜", """
                SELECT c.name AS ì¹´í…Œê³ ë¦¬ëª…, COUNT(pcd.id) AS ë°ì´í„°ìˆ˜
                FROM categories c
                LEFT JOIN project_category_data pcd ON c.id = pcd.category_id
                GROUP BY c.id, c.name
            """),
            
            ("ì—°ë„ë³„ ì˜ˆì‚° í•©ê³„", """
                SELECT fiscal_year AS ì—°ë„, 
                       COUNT(*) AS ì˜ˆì‚°í•­ëª©ìˆ˜,
                       SUM(planned_amount) AS ì´ì˜ˆì‚°
                FROM budgets
                GROUP BY fiscal_year
                ORDER BY fiscal_year
            """)
        ]
        
        for title, query in verification_queries:
            try:
                self.cursor.execute(query)
                results = self.cursor.fetchall()
                
                logger.info(f"\nğŸ“Š {title}:")
                for row in results[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                    logger.info(f"  {row}")
                    
            except Error as e:
                logger.error(f"ê²€ì¦ ì¿¼ë¦¬ ì‹¤íŒ¨ ({title}): {e}")
    
    def print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ í†µê³„")
        print("="*80)
        print(f"âœ… ìƒì„±ëœ í…Œì´ë¸”: {self.stats['tables_created']}ê°œ")
        print(f"âœ… ì ì¬ëœ ë ˆì½”ë“œ: {self.stats['records_inserted']:,}ê°œ")
        print(f"âœ… ì‹¤í–‰ëœ ë°°ì¹˜: {self.stats['batch_count']}ê°œ")
        
        if self.stats["errors"]:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ:")
            for error in self.stats["errors"]:
                print(f"  - {error}")
        
        print("="*80 + "\n")
    
    def load(self):
        """ì „ì²´ ì ì¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            with self.db_connection():
                logger.info("ğŸš€ ê°œì„ ëœ DB ì ì¬ ì‹œì‘")
                
                # 1. í…Œì´ë¸” ìƒì„±
                logger.info("\n1. í…Œì´ë¸” ìƒì„± ì¤‘...")
                self.create_tables()
                
                # 2. ë°ì´í„° ì ì¬
                logger.info("\n2. CSV ë°ì´í„° ì ì¬ ì¤‘...")
                self.load_csv_data()
                
                # 3. ë°ì´í„° ê²€ì¦
                logger.info("\n3. ë°ì´í„° ê²€ì¦ ì¤‘...")
                self.verify_data()
                
                # 4. í†µê³„ ì¶œë ¥
                self.print_statistics()
                
                logger.info("âœ… DB ì ì¬ ì™„ë£Œ!")
                return True
                
        except Exception as e:
            logger.error(f"âŒ DB ì ì¬ ì‹¤íŒ¨: {e}")
            self.print_statistics()
            return False


def load_to_mysql_improved(csv_dir: str) -> bool:
    """ê°œì„ ëœ MySQL ì ì¬ ì‹¤í–‰ í•¨ìˆ˜"""
    loader = ImprovedDBLoader(csv_dir)
    return loader.load()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    csv_folder = "normalized_output_improved"
    
    if Path(csv_folder).exists():
        success = load_to_mysql_improved(csv_folder)
        if success:
            print("âœ… DB ì ì¬ ì„±ê³µ!")
        else:
            print("âŒ DB ì ì¬ ì‹¤íŒ¨!")
    else:
        print(f"âŒ CSV í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_folder}")