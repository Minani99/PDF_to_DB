"""
PDFì—ì„œ í…Œì´ë¸”ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë“ˆ
ì •ë¶€/ê³µê³µê¸°ê´€ ë¬¸ì„œ êµ¬ì¡°ì— ìµœì í™”
"""
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
import logging
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    import pdfplumber
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    logger.warning("pdfplumber not installed. Using sample data mode.")


class GovernmentPDFExtractor:
    """ì •ë¶€ ë¬¸ì„œ PDF ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self, pdf_path: str = None, output_dir: str = "output"):
        """
        Args:
            pdf_path: ì…ë ¥ PDF íŒŒì¼ ê²½ë¡œ
            output_dir: ì¶œë ¥ JSON ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.pdf_path = Path(pdf_path) if pdf_path else None
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ì¹´í…Œê³ ë¦¬ íŒ¨í„´
        self.category_patterns = {
            'overview': [r'\(1\)', r'ì‚¬ì—…ê°œìš”', r'ì‚¬ì—…ëª©í‘œ', r'ì£¼ê´€ê¸°ê´€'],
            'performance': [r'\(2\)', r'ì¶”ì§„ì‹¤ì ', r'ì„±ê³¼ì§€í‘œ', r'íŠ¹í—ˆ', r'ë…¼ë¬¸'],
            'plan': [r'\(3\)', r'ì¶”ì§„ê³„íš', r'ì¼ì •', r'ì˜ˆì‚°', r'ì‚¬ì—…ë¹„']
        }
        
        # ì¶”ì¶œ í†µê³„
        self.stats = {
            'total_pages': 0,
            'total_tables': 0,
            'total_rows': 0,
            'categories_found': set(),
            'sub_projects': []
        }
    
    def extract(self) -> Dict[str, Any]:
        """PDFì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        if not PDF_AVAILABLE or not self.pdf_path:
            logger.info("Using sample data mode")
            return self._generate_sample_data()
        
        try:
            logger.info(f"ğŸš€ PDF ì¶”ì¶œ ì‹œì‘: {self.pdf_path.name}")
            
            result = {
                "metadata": {
                    "source_file": self.pdf_path.name,
                    "extraction_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    "document_year": self._detect_year(),
                    "total_pages": 0
                },
                "pages": []
            }
            
            with pdfplumber.open(self.pdf_path) as pdf:
                result["metadata"]["total_pages"] = len(pdf.pages)
                self.stats['total_pages'] = len(pdf.pages)
                
                for page_num, page in enumerate(pdf.pages, 1):
                    page_data = self._process_page(page, page_num)
                    if page_data:
                        result["pages"].append(page_data)
                
            self._print_statistics()
            
            # JSON ì €ì¥
            output_file = self.output_dir / f"{self.pdf_path.stem}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {output_file}")
            return result
            
        except Exception as e:
            logger.error(f"PDF ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._generate_sample_data()
    
    def _process_page(self, page, page_num: int) -> Dict[str, Any]:
        """í˜ì´ì§€ ì²˜ë¦¬"""
        logger.info(f"ğŸ“„ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘...")
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        full_text = page.extract_text() or ""
        
        # ì¹´í…Œê³ ë¦¬ ê°ì§€
        category = self._detect_category(full_text)
        if category:
            self.stats['categories_found'].add(category)
        
        # ë‚´ì—­ì‚¬ì—… ê°ì§€ (í…ìŠ¤íŠ¸ì—ì„œ)
        sub_project = self._detect_sub_project(full_text)

        # í…Œì´ë¸” ì¶”ì¶œ
        tables = page.extract_tables()

        # í…Œì´ë¸”ì—ì„œë„ ë‚´ì—­ì‚¬ì—…ëª… ì°¾ê¸°
        if not sub_project and tables:
            for table in tables:
                for row in table:
                    if row and len(row) >= 2:
                        # "ë‚´ì—­ì‚¬ì—…ëª…" ì°¾ê¸°
                        if 'ë‚´ì—­ì‚¬ì—…' in str(row[0]):
                            sub_project = str(row[1]).strip()
                            break
                if sub_project:
                    break

        if sub_project and sub_project not in self.stats['sub_projects']:
            self.stats['sub_projects'].append(sub_project)
            logger.info(f"  âœ“ ë‚´ì—­ì‚¬ì—… ë°œê²¬: {sub_project}")
        
        page_data = {
            "page_number": page_num,
            "full_text": full_text,
            "category": category,
            "sub_project": sub_project,
            "tables": []
        }
        
        if tables:
            logger.info(f"  âœ“ {len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
            self.stats['total_tables'] += len(tables)
            
            for table_idx, table in enumerate(tables, 1):
                processed_table = self._process_table(table, category)
                if processed_table:
                    page_data["tables"].append({
                        "table_number": table_idx,
                        "category": category,
                        "rows": len(processed_table),
                        "columns": len(processed_table[0]) if processed_table else 0,
                        "data": processed_table
                    })
                    self.stats['total_rows'] += len(processed_table)
        
        return page_data
    
    def _process_table(self, table: List[List], category: str) -> List[List]:
        """í…Œì´ë¸” ì²˜ë¦¬ ë° ì •ì œ"""
        if not table:
            return []
        
        # ë¹ˆ í–‰ ì œê±° ë° ë„ì–´ì“°ê¸° ë¬¸ì œ ìˆ˜ì •
        cleaned_table = []
        for row in table:
            if row and any(cell for cell in row if cell and str(cell).strip()):
                # PDF íŒŒì‹± ì‹œ ë„ì–´ì“°ê¸° ë¬¸ì œ ìˆ˜ì • (ì˜ˆ: "ì • ë¶€" -> "ì •ë¶€")
                cleaned_row = []
                for cell in row:
                    if cell:
                        cell_str = str(cell).strip()
                        # í•œê¸€ ë‹¨ì–´ ì¤‘ê°„ì— ê³µë°±ì´ í•˜ë‚˜ì”© ë¼ì–´ìˆëŠ” ê²½ìš° ì œê±°
                        # "ì • ë¶€" -> "ì •ë¶€", "ë¯¼ ê°„" -> "ë¯¼ê°„"
                        if re.match(r'^[\u3131-\u3163\uac00-\ud7a3]\s[\u3131-\u3163\uac00-\ud7a3]$', cell_str):
                            cell_str = cell_str.replace(' ', '')
                        cleaned_row.append(cell_str)
                    else:
                        cleaned_row.append("")
                cleaned_table.append(cleaned_row)
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ìˆ˜ ì²˜ë¦¬
        if category == 'performance' and cleaned_table:
            cleaned_table = self._enhance_performance_table(cleaned_table)
        elif category == 'plan' and cleaned_table:
            cleaned_table = self._enhance_plan_table(cleaned_table)
        
        return cleaned_table
    
    def _enhance_performance_table(self, table: List[List]) -> List[List]:
        """ì„±ê³¼ í…Œì´ë¸” í–¥ìƒ"""
        # í—¤ë”ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
        if table and not any('ì„±ê³¼' in str(cell) for cell in table[0]):
            # ë°ì´í„° íŒ¨í„´ìœ¼ë¡œ í—¤ë” ì¶”ë¡ 
            if any('íŠ¹í—ˆ' in str(row[0]) for row in table):
                table.insert(0, ['ì„±ê³¼ì§€í‘œ', 'ì„¸ë¶€í•­ëª©', 'ì‹¤ì '])
            elif len(table[0]) >= 4 and all(self._is_number(cell) for cell in table[0][1:]):
                table.insert(0, ['êµ¬ë¶„', 'êµ­ë‚´ì¶œì›', 'êµ­ë‚´ë“±ë¡', 'êµ­ì™¸ì¶œì›', 'êµ­ì™¸ë“±ë¡'])
        
        return table
    
    def _enhance_plan_table(self, table: List[List]) -> List[List]:
        """ê³„íš í…Œì´ë¸” í–¥ìƒ"""
        # ì¼ì • í…Œì´ë¸” ê°ì§€ ë° í–¥ìƒ
        if table and any('ë¶„ê¸°' in str(cell) for row in table for cell in row):
            if not any('ì¶”ì§„ì¼ì •' in str(cell) for cell in table[0]):
                table.insert(0, ['ì¶”ì§„ì¼ì •', 'ê³¼ì œëª…', 'ì„¸ë¶€ë‚´ìš©'])
        
        # ì˜ˆì‚° í…Œì´ë¸” ê°ì§€ ë° í–¥ìƒ
        elif table and any('ì˜ˆì‚°' in str(cell) or 'ë°±ë§Œì›' in str(cell) for row in table for cell in row):
            if not any('ì—°ë„' in str(cell) for cell in table[0]):
                table.insert(0, ['ì—°ë„', 'ì´ì˜ˆì‚°', 'ì •ë¶€', 'ë¯¼ê°„', 'ê¸°íƒ€'])
        
        return table
    
    def _detect_category(self, text: str) -> Optional[str]:
        """ì¹´í…Œê³ ë¦¬ ê°ì§€"""
        text_lower = text.lower()
        
        for category, patterns in self.category_patterns.items():
            if any(re.search(pattern.lower(), text_lower) for pattern in patterns):
                return category
        
        return None
    
    def _detect_sub_project(self, text: str) -> Optional[str]:
        """ë‚´ì—­ì‚¬ì—…ëª… ê°ì§€"""
        patterns = [
            r'ë‚´ì—­ì‚¬ì—…ëª…\s*[:ï¼š]\s*([^\n]+)',
            r'ë‚´ì—­ì‚¬ì—…\s*[:ï¼š]\s*([^\n]+)',
            r'â—¦\s*([^â—¦\n]+(?:ê¸°ìˆ ê°œë°œ|ì—°êµ¬ê°œë°œ|ì‚¬ì—…))',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1).strip()
        
        return None
    
    def _detect_year(self) -> int:
        """ë¬¸ì„œ ì—°ë„ ê°ì§€"""
        current_year = datetime.now().year
        
        if self.pdf_path and self.pdf_path.stem:
            # íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì¶”ì¶œ
            year_match = re.search(r'(20\d{2})', self.pdf_path.stem)
            if year_match:
                return int(year_match.group(1))
        
        return current_year
    
    def _is_number(self, text: str) -> bool:
        """ìˆ«ì ì—¬ë¶€ í™•ì¸"""
        try:
            float(str(text).replace(',', '').replace('ê±´', '').replace('í¸', '').strip())
            return True
        except:
            return False
    
    def _generate_sample_data(self) -> Dict[str, Any]:
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„± (PDF ì—†ì„ ë•Œ)"""
        logger.info("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘...")
        
        return {
            "metadata": {
                "source_file": "sample_data.pdf",
                "extraction_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "document_year": 2024,
                "total_pages": 12
            },
            "pages": [
                {
                    "page_number": 1,
                    "full_text": "1. ì„¸ë¶€ì‚¬ì—…ëª…: ë°”ì´ì˜¤Â·ì˜ë£Œê¸°ìˆ ê°œë°œ\në‚´ì—­ì‚¬ì—…ëª…: ë‡Œì—°êµ¬",
                    "category": None,
                    "sub_project": "ë‡Œì—°êµ¬",
                    "tables": [{
                        "table_number": 1,
                        "category": None,
                        "data": [
                            ["í•­ëª©", "ë‚´ìš©"],
                            ["ì„¸ë¶€ì‚¬ì—…ëª…", "ë°”ì´ì˜¤Â·ì˜ë£Œê¸°ìˆ ê°œë°œ"],
                            ["ë‚´ì—­ì‚¬ì—…ëª…", "ë‡Œì—°êµ¬"],
                            ["ë‹´ë‹¹ë¶€ì²˜", "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€"]
                        ]
                    }]
                },
                {
                    "page_number": 2,
                    "full_text": "(1) ì‚¬ì—…ê°œìš”",
                    "category": "overview",
                    "sub_project": "ë‡Œì—°êµ¬",
                    "tables": [{
                        "table_number": 1,
                        "category": "overview",
                        "data": [
                            ["êµ¬ë¶„", "ë‚´ìš©"],
                            ["ì‚¬ì—…ëª©í‘œ", "ë‡Œê³¼í•™ ì›ì²œê¸°ìˆ  í™•ë³´ ë° ë‡Œì§ˆí™˜ ê·¹ë³µ"],
                            ["ì£¼ê´€ê¸°ê´€", "í•œêµ­ë‡Œì—°êµ¬ì›"],
                            ["ì‚¬ì—…ë‚´ìš©", "ë‡Œì§€ë„ êµ¬ì¶•, ë‡Œì§ˆí™˜ ì§„ë‹¨/ì¹˜ë£Œ ê¸°ìˆ  ê°œë°œ"]
                        ]
                    }]
                },
                {
                    "page_number": 3,
                    "full_text": "(2) ì¶”ì§„ì‹¤ì ",
                    "category": "performance",
                    "sub_project": "ë‡Œì—°êµ¬",
                    "tables": [{
                        "table_number": 1,
                        "category": "performance",
                        "data": [
                            ["ì„±ê³¼ì§€í‘œ", "ì„¸ë¶€í•­ëª©", "ì‹¤ì "],
                            ["íŠ¹í—ˆ", "êµ­ë‚´ì¶œì›", "1,001"],
                            ["íŠ¹í—ˆ", "êµ­ë‚´ë“±ë¡", "125"],
                            ["íŠ¹í—ˆ", "êµ­ì™¸ì¶œì›", "74"],
                            ["íŠ¹í—ˆ", "êµ­ì™¸ë“±ë¡", "10"],
                            ["ë…¼ë¬¸", "SCIE", "5,977"],
                            ["ë…¼ë¬¸", "IF10ì´ìƒ", "234"],
                            ["ì¸ë ¥ì–‘ì„±", "ë°•ì‚¬", "156"],
                            ["ì¸ë ¥ì–‘ì„±", "ì„ì‚¬", "289"]
                        ]
                    }]
                },
                {
                    "page_number": 4,
                    "full_text": "(3) ì¶”ì§„ê³„íš",
                    "category": "plan",
                    "sub_project": "ë‡Œì—°êµ¬",
                    "tables": [
                        {
                            "table_number": 1,
                            "category": "plan",
                            "data": [
                                ["ì¶”ì§„ì¼ì •", "ê³¼ì œëª…", "ì„¸ë¶€ë‚´ìš©"],
                                ["1/4ë¶„ê¸°~2/4ë¶„ê¸°", "ë‡Œì§€ë„ êµ¬ì¶•", "ê³ í•´ìƒë„ ë‡Œì˜ìƒ ë°ì´í„° ìˆ˜ì§‘"],
                                ["2/4ë¶„ê¸°~3/4ë¶„ê¸°", "AI ë¶„ì„ í”Œë«í¼", "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë‡Œì˜ìƒ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬ì¶•"],
                                ["3/4ë¶„ê¸°~4/4ë¶„ê¸°", "ì„ìƒ ê²€ì¦", "ë‡Œì§ˆí™˜ ì§„ë‹¨ ì •í™•ë„ ê²€ì¦"],
                                ["ì—°ì¤‘", "ì¸ë ¥ ì–‘ì„±", "ì „ë¬¸ ì—°êµ¬ì¸ë ¥ êµìœ¡ í”„ë¡œê·¸ë¨ ìš´ì˜"]
                            ]
                        },
                        {
                            "table_number": 2,
                            "category": "plan",
                            "data": [
                                ["ì—°ë„", "ì´ì˜ˆì‚°", "ì •ë¶€", "ë¯¼ê°„", "ì§€ë°©ë¹„"],
                                ["2023(ì‹¤ì )", "45,200", "35,000", "8,200", "2,000"],
                                ["2024(ê³„íš)", "52,300", "40,000", "10,300", "2,000"],
                                ["2025(ê³„íš)", "58,500", "44,000", "12,500", "2,000"]
                            ]
                        }
                    ]
                }
            ]
        }
    
    def _print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        logger.info(f"""
ğŸ“Š ì¶”ì¶œ í†µê³„:
- ì´ í˜ì´ì§€: {self.stats['total_pages']}
- ì´ í…Œì´ë¸”: {self.stats['total_tables']}
- ì´ ë°ì´í„° í–‰: {self.stats['total_rows']}
- ì¹´í…Œê³ ë¦¬: {', '.join(self.stats['categories_found'])}
- ë‚´ì—­ì‚¬ì—…: {len(self.stats['sub_projects'])}ê°œ
  {', '.join(self.stats['sub_projects'])}
        """)


def extract_pdf_to_json(pdf_path: str = None, output_dir: str = "output") -> Dict[str, Any]:
    """
    PDFë¥¼ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    
    Returns:
        ì¶”ì¶œëœ JSON ë°ì´í„°
    """
    extractor = GovernmentPDFExtractor(pdf_path, output_dir)
    return extractor.extract()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import sys
    
    if len(sys.argv) > 1:
        pdf_file = sys.argv[1]
        result = extract_pdf_to_json(pdf_file)
    else:
        # ìƒ˜í”Œ ë°ì´í„° ëª¨ë“œ
        result = extract_pdf_to_json()
    
    if result:
        print(f"\nâœ… ì¶”ì¶œ ì™„ë£Œ! í˜ì´ì§€: {len(result['pages'])}ê°œ")