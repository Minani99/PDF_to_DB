"""
ì •ë¶€/ê³µê³µê¸°ê´€ í‘œì¤€ ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ ëª¨ë“ˆ
ì›ë³¸ ë°ì´í„° + ì •ê·œí™” ë°ì´í„° ë¶„ë¦¬ ì €ì¥
"""
import pymysql
import pandas as pd
import json
from pathlib import Path
from typing import Dict, List, Any
import logging
from datetime import datetime
from decimal import Decimal

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class GovernmentStandardDBLoader:
    """ì •ë¶€ í‘œì¤€ DB ì ì¬ í´ë˜ìŠ¤"""
    
    def __init__(self, db_config: Dict[str, Any], csv_dir: str):
        """
        Args:
            db_config: MySQL ì—°ê²° ì„¤ì •
            csv_dir: ì •ê·œí™”ëœ CSV íŒŒì¼ ë””ë ‰í† ë¦¬
        """
        self.db_config = db_config
        self.csv_dir = Path(csv_dir)
        self.connection = None
        self.cursor = None
        
        # í…Œì´ë¸” ìƒì„± ìˆœì„œ (ì™¸ë˜í‚¤ ì˜ì¡´ì„± ê³ ë ¤)
        self.tables = [
            'sub_projects',
            'raw_data',
            'normalized_schedules',
            'normalized_performances',
            'normalized_budgets',
            'normalized_overviews',
            'key_achievements',
            'plan_details',
            'data_statistics'
        ]
        
        # ì ì¬ í†µê³„
        self.load_stats = {
            'tables_created': 0,
            'total_records': 0,
            'records_by_table': {},
            'errors': []
        }
    
    def connect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            db_name = self.db_config.get('database', 'government_standard')

            # ë¨¼ì € ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (ì—†ìœ¼ë©´)
            logger.info(f"ğŸ”Œ ë°ì´í„°ë² ì´ìŠ¤ '{db_name}' í™•ì¸ ì¤‘...")
            temp_conn = pymysql.connect(
                host=self.db_config.get('host', 'localhost'),
                user=self.db_config.get('user', 'root'),
                password=self.db_config['password'],
                charset='utf8mb4'
            )

            with temp_conn.cursor() as cursor:
                cursor.execute(f"""
                    CREATE DATABASE IF NOT EXISTS {db_name}
                    CHARACTER SET utf8mb4 
                    COLLATE utf8mb4_unicode_ci
                """)
                temp_conn.commit()
                logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ '{db_name}' ì¤€ë¹„ ì™„ë£Œ")

            temp_conn.close()

            # ì´ì œ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°
            self.connection = pymysql.connect(
                host=self.db_config.get('host', 'localhost'),
                user=self.db_config.get('user', 'root'),
                password=self.db_config['password'],
                database=db_name,
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )
            self.cursor = self.connection.cursor()
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    def _create_database_if_not_exists(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - connect()ì—ì„œ ì²˜ë¦¬)"""
        pass

    def drop_existing_tables(self):
        """ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ"""
        logger.info("ğŸ—‘ï¸ ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ ì¤‘...")
        
        # ì™¸ë˜í‚¤ ì œì•½ ì„ì‹œ í•´ì œ
        self.cursor.execute("SET FOREIGN_KEY_CHECKS = 0")
        
        # ì—­ìˆœìœ¼ë¡œ ì‚­ì œ
        for table in reversed(self.tables):
            try:
                self.cursor.execute(f"DROP TABLE IF EXISTS {table}")
                logger.info(f"  âœ“ {table} í…Œì´ë¸” ì‚­ì œ")
            except Exception as e:
                logger.warning(f"  ! {table} í…Œì´ë¸” ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        # ì™¸ë˜í‚¤ ì œì•½ ì¬ì„¤ì •
        self.cursor.execute("SET FOREIGN_KEY_CHECKS = 1")
        self.connection.commit()
    
    def create_tables(self):
        """í…Œì´ë¸” ìƒì„±"""
        logger.info("ğŸ“Š í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        # 1. ë‚´ì—­ì‚¬ì—… ë§ˆìŠ¤í„°
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS sub_projects (
                id INT PRIMARY KEY,
                project_code VARCHAR(100),
                department_name VARCHAR(200),
                main_project_name VARCHAR(500),
                sub_project_name VARCHAR(500),
                document_year INT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_project_code (project_code),
                INDEX idx_sub_project_name (sub_project_name),
                INDEX idx_document_year (document_year)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)
        
        # 2. ì›ë³¸ ë°ì´í„° (ê°ì‚¬ ì¶”ì ìš©)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS raw_data (
                id INT PRIMARY KEY,
                sub_project_id INT,
                data_type VARCHAR(50),
                data_year INT,
                raw_content JSON,
                page_number INT,
                table_index INT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) 
                    ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_data_type (data_type),
                INDEX idx_data_year (data_year),
                INDEX idx_page (page_number)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)
        
        # 3. ì •ê·œí™”ëœ ì¼ì •
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS normalized_schedules (
                id INT PRIMARY KEY,
                sub_project_id INT,
                raw_data_id INT,
                year INT,
                quarter INT,
                month_start INT,
                month_end INT,
                start_date DATE,
                end_date DATE,
                task_category VARCHAR(200),
                task_description TEXT,
                original_period VARCHAR(100),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) 
                    ON DELETE CASCADE ON UPDATE CASCADE,
                FOREIGN KEY (raw_data_id) REFERENCES raw_data(id) 
                    ON DELETE SET NULL ON UPDATE CASCADE,
                INDEX idx_year_quarter (year, quarter),
                INDEX idx_dates (start_date, end_date),
                INDEX idx_category (task_category)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)
        
        # 4. ì •ê·œí™”ëœ ì„±ê³¼
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS normalized_performances (
                id INT PRIMARY KEY,
                sub_project_id INT,
                raw_data_id INT,
                performance_year INT,
                indicator_category VARCHAR(100),
                indicator_type VARCHAR(200),
                value INT,
                unit VARCHAR(50),
                original_text TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) 
                    ON DELETE CASCADE ON UPDATE CASCADE,
                FOREIGN KEY (raw_data_id) REFERENCES raw_data(id) 
                    ON DELETE SET NULL ON UPDATE CASCADE,
                INDEX idx_year (performance_year),
                INDEX idx_category (indicator_category),
                INDEX idx_type (indicator_type)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)
        
        # 5. ì •ê·œí™”ëœ ì˜ˆì‚°
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS normalized_budgets (
                id INT PRIMARY KEY,
                sub_project_id INT,
                raw_data_id INT,
                budget_year INT,
                budget_category VARCHAR(100),
                budget_type VARCHAR(100),
                amount DECIMAL(15, 2),
                currency VARCHAR(10) DEFAULT 'KRW',
                is_actual BOOLEAN DEFAULT FALSE,
                original_text TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) 
                    ON DELETE CASCADE ON UPDATE CASCADE,
                FOREIGN KEY (raw_data_id) REFERENCES raw_data(id) 
                    ON DELETE SET NULL ON UPDATE CASCADE,
                INDEX idx_year (budget_year),
                INDEX idx_category (budget_category),
                INDEX idx_type (budget_type)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)
        
        # 6. ì •ê·œí™”ëœ ì‚¬ì—…ê°œìš”
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS normalized_overviews (
                id INT PRIMARY KEY,
                sub_project_id INT,
                raw_data_id INT,
                overview_type VARCHAR(100),
                main_project TEXT,
                sub_project TEXT,
                field TEXT,
                project_type TEXT,
                objective TEXT,
                content TEXT,
                managing_dept TEXT,
                managing_org TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) 
                    ON DELETE CASCADE ON UPDATE CASCADE,
                FOREIGN KEY (raw_data_id) REFERENCES raw_data(id) 
                    ON DELETE SET NULL ON UPDATE CASCADE,
                INDEX idx_type (overview_type)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)
        
        # 7. ëŒ€í‘œì„±ê³¼ (key_achievements)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS key_achievements (
                id INT PRIMARY KEY,
                sub_project_id INT,
                achievement_year INT,
                achievement_order INT,
                description TEXT,
                page_number INT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) 
                    ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_year (achievement_year)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)

        # 8. ì£¼ìš” ì¶”ì§„ê³„íš ë‚´ìš© (plan_details)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS plan_details (
                id INT PRIMARY KEY,
                sub_project_id INT,
                plan_year INT,
                plan_order INT,
                description TEXT,
                page_number INT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) 
                    ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_year (plan_year)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)

        # 9. ë°ì´í„° í†µê³„ (ê²€ì¦ìš©)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS data_statistics (
                id INT PRIMARY KEY AUTO_INCREMENT,
                sub_project_id INT,
                table_name VARCHAR(100),
                record_count INT,
                data_year INT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (sub_project_id) REFERENCES sub_projects(id) 
                    ON DELETE CASCADE ON UPDATE CASCADE,
                INDEX idx_table (table_name),
                INDEX idx_year (data_year)
            ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
        """)
        
        self.connection.commit()
        logger.info("âœ… ëª¨ë“  í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        self.load_stats['tables_created'] = len(self.tables)

    def load_csv_to_table(self, table_name: str) -> int:
        """CSV íŒŒì¼ì„ í…Œì´ë¸”ë¡œ ì ì¬"""
        csv_file = self.csv_dir / f"{table_name}.csv"
        
        if not csv_file.exists():
            logger.warning(f"âš ï¸ {csv_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        try:
            # CSV ì½ê¸°
            df = pd.read_csv(csv_file, encoding='utf-8-sig')
            
            if df.empty:
                logger.warning(f"âš ï¸ {table_name}ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return 0

            # NULL ê°’ ì²˜ë¦¬ (NaNì„ Noneìœ¼ë¡œ ë³€í™˜)
            df = df.replace({pd.NA: None, pd.NaT: None})
            df = df.where(pd.notna(df), None)
            
            # ë¹ˆ ë¬¸ìì—´ì„ Noneìœ¼ë¡œ ì²˜ë¦¬
            for col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].apply(lambda x: None if x == '' or (isinstance(x, str) and x.strip() == '') else x)

            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            date_columns = ['start_date', 'end_date', 'created_at']
            for col in date_columns:
                if col in df.columns:
                    # ë‚ ì§œ í˜•ì‹ íŒŒì‹±
                    df[col] = pd.to_datetime(df[col], errors='coerce')
                    # NaTëŠ” Noneìœ¼ë¡œ ë³€í™˜
                    df[col] = df[col].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notna(x) else None)

            # JSON ì»¬ëŸ¼ ì²˜ë¦¬
            if 'raw_content' in df.columns:
                df['raw_content'] = df['raw_content'].apply(
                    lambda x: json.dumps(json.loads(x), ensure_ascii=False) if x and pd.notna(x) else None
                )
            
            # ë°ì´í„° ì ì¬
            records = df.to_dict('records')
            
            if records:
                # ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
                columns = list(records[0].keys())
                
                # INSERT ì¿¼ë¦¬ ìƒì„±
                placeholders = ', '.join(['%s'] * len(columns))
                columns_str = ', '.join([f"`{col}`" for col in columns])
                
                query = f"""
                    INSERT INTO {table_name} ({columns_str})
                    VALUES ({placeholders})
                """
                
                # ë°°ì¹˜ë¡œ ì‚½ì…
                batch_size = 100
                total_inserted = 0
                
                for i in range(0, len(records), batch_size):
                    batch = records[i:i + batch_size]
                    values = []
                    
                    for record in batch:
                        # ê° ë ˆì½”ë“œë¥¼ íŠœí”Œë¡œ ë³€í™˜
                        row_values = []
                        for col in columns:
                            val = record.get(col)
                            # NaN ì²´í¬ ë° ì²˜ë¦¬
                            if pd.isna(val):
                                row_values.append(None)
                            elif isinstance(val, (int, float)):
                                # float NaN ì²´í¬
                                if val != val:  # NaNì€ ìê¸° ìì‹ ê³¼ ê°™ì§€ ì•ŠìŒ
                                    row_values.append(None)
                                else:
                                    row_values.append(val)
                            else:
                                row_values.append(val)
                        values.append(tuple(row_values))
                    
                    self.cursor.executemany(query, values)
                    total_inserted += len(batch)
                    
                    if total_inserted % 1000 == 0:
                        logger.info(f"  {table_name}: {total_inserted}ê±´ ì ì¬ ì¤‘...")
                
                self.connection.commit()
                logger.info(f"âœ… {table_name}: {total_inserted}ê±´ ì ì¬ ì™„ë£Œ")
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.load_stats['records_by_table'][table_name] = total_inserted
                self.load_stats['total_records'] += total_inserted
                
                return total_inserted
                
        except Exception as e:
            logger.error(f"âŒ {table_name} ì ì¬ ì‹¤íŒ¨: {e}")
            self.load_stats['errors'].append(f"{table_name}: {str(e)}")
            self.connection.rollback()
            return 0
    
    def load_all_tables(self):
        """ëª¨ë“  í…Œì´ë¸” ì ì¬"""
        logger.info("ğŸ“¥ ë°ì´í„° ì ì¬ ì‹œì‘...")
        
        for table_name in self.tables:
            record_count = self.load_csv_to_table(table_name)
            
            # í†µê³„ í…Œì´ë¸” ì—…ë°ì´íŠ¸
            if record_count > 0 and table_name != 'data_statistics':
                self._update_statistics(table_name, record_count)
        
        logger.info("âœ… ëª¨ë“  ë°ì´í„° ì ì¬ ì™„ë£Œ")
        self._print_load_summary()
    
    def _update_statistics(self, table_name: str, record_count: int):
        """í†µê³„ í…Œì´ë¸” ì—…ë°ì´íŠ¸"""
        try:
            # ê° ë‚´ì—­ì‚¬ì—…ë³„ í†µê³„
            query = f"""
                INSERT INTO data_statistics (sub_project_id, table_name, record_count, data_year)
                SELECT sub_project_id, %s, COUNT(*), YEAR(CURRENT_DATE())
                FROM {table_name}
                WHERE sub_project_id IS NOT NULL
                GROUP BY sub_project_id
            """
            
            if 'sub_project_id' in self._get_table_columns(table_name):
                self.cursor.execute(query, (table_name,))
                self.connection.commit()
                
        except Exception as e:
            logger.warning(f"í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _get_table_columns(self, table_name: str) -> List[str]:
        """í…Œì´ë¸” ì»¬ëŸ¼ ëª©ë¡ ì¡°íšŒ"""
        self.cursor.execute(f"""
            SELECT COLUMN_NAME 
            FROM INFORMATION_SCHEMA.COLUMNS 
            WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
        """, (self.db_config.get('database', 'government_standard'), table_name))
        
        return [row['COLUMN_NAME'] for row in self.cursor.fetchall()]
    
    def verify_data_integrity(self) -> Dict[str, Any]:
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        logger.info("ğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì¤‘...")
        
        verification = {
            'total_sub_projects': 0,
            'raw_data_count': 0,
            'normalized_counts': {},
            'orphan_records': {},
            'missing_data': []
        }
        
        # 1. ë‚´ì—­ì‚¬ì—… ìˆ˜
        self.cursor.execute("SELECT COUNT(*) as cnt FROM sub_projects")
        verification['total_sub_projects'] = self.cursor.fetchone()['cnt']
        
        # 2. ì›ë³¸ ë°ì´í„° ìˆ˜
        self.cursor.execute("SELECT COUNT(*) as cnt FROM raw_data")
        verification['raw_data_count'] = self.cursor.fetchone()['cnt']
        
        # 3. ì •ê·œí™” ë°ì´í„° ìˆ˜
        normalized_tables = ['normalized_schedules', 'normalized_performances', 
                           'normalized_budgets', 'normalized_overviews']
        
        for table in normalized_tables:
            self.cursor.execute(f"SELECT COUNT(*) as cnt FROM {table}")
            verification['normalized_counts'][table] = self.cursor.fetchone()['cnt']
        
        # 4. ê³ ì•„ ë ˆì½”ë“œ í™•ì¸
        for table in normalized_tables:
            self.cursor.execute(f"""
                SELECT COUNT(*) as cnt 
                FROM {table} t
                LEFT JOIN sub_projects s ON t.sub_project_id = s.id
                WHERE s.id IS NULL
            """)
            orphan_count = self.cursor.fetchone()['cnt']
            if orphan_count > 0:
                verification['orphan_records'][table] = orphan_count
        
        # 5. ëˆ„ë½ ë°ì´í„° í™•ì¸
        self.cursor.execute("""
            SELECT s.sub_project_name, 
                   COUNT(DISTINCT ns.id) as schedules,
                   COUNT(DISTINCT np.id) as performances,
                   COUNT(DISTINCT nb.id) as budgets
            FROM sub_projects s
            LEFT JOIN normalized_schedules ns ON s.id = ns.sub_project_id
            LEFT JOIN normalized_performances np ON s.id = np.sub_project_id
            LEFT JOIN normalized_budgets nb ON s.id = nb.sub_project_id
            GROUP BY s.id, s.sub_project_name
            HAVING schedules = 0 OR performances = 0 OR budgets = 0
        """)
        
        missing_data = self.cursor.fetchall()
        if missing_data:
            verification['missing_data'] = missing_data
        
        # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        logger.info(f"""
ğŸ“Š ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ê²°ê³¼:
- ì´ ë‚´ì—­ì‚¬ì—…: {verification['total_sub_projects']}ê°œ
- ì›ë³¸ ë°ì´í„°: {verification['raw_data_count']}ê±´
- ì •ê·œí™” ë°ì´í„°:
  â€¢ ì¼ì •: {verification['normalized_counts'].get('normalized_schedules', 0)}ê±´
  â€¢ ì„±ê³¼: {verification['normalized_counts'].get('normalized_performances', 0)}ê±´
  â€¢ ì˜ˆì‚°: {verification['normalized_counts'].get('normalized_budgets', 0)}ê±´
  â€¢ ê°œìš”: {verification['normalized_counts'].get('normalized_overviews', 0)}ê±´
- ê³ ì•„ ë ˆì½”ë“œ: {len(verification['orphan_records'])}ê°œ í…Œì´ë¸”
- ëˆ„ë½ ë°ì´í„° ì‚¬ì—…: {len(verification['missing_data'])}ê°œ
        """)
        
        return verification
    
    def _print_load_summary(self):
        """ì ì¬ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š ë°ì´í„° ì ì¬ ìš”ì•½")
        print("="*60)
        print(f"âœ… ìƒì„±ëœ í…Œì´ë¸”: {self.load_stats['tables_created']}ê°œ")
        print(f"âœ… ì´ ì ì¬ ë ˆì½”ë“œ: {self.load_stats['total_records']:,}ê±´")
        print("\ní…Œì´ë¸”ë³„ ì ì¬ í˜„í™©:")
        
        for table, count in self.load_stats['records_by_table'].items():
            print(f"  â€¢ {table}: {count:,}ê±´")
        
        if self.load_stats['errors']:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {len(self.load_stats['errors'])}ê±´")
            for error in self.load_stats['errors']:
                print(f"  - {error}")
        
        print("="*60)
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.cursor:
            self.cursor.close()
        if self.connection:
            self.connection.close()
        logger.info("ğŸ”Œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    from config import MYSQL_CONFIG
    
    # ì •ë¶€ í‘œì¤€ DB ì„¤ì •
    db_config = MYSQL_CONFIG.copy()
    db_config['database'] = 'government_standard'
    
    # CSV ë””ë ‰í† ë¦¬
    csv_dir = "normalized_output_government"
    
    # ì ì¬ ì‹¤í–‰
    loader = GovernmentStandardDBLoader(db_config, csv_dir)
    
    try:
        # ì—°ê²°
        loader.connect()
        
        # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
        loader.drop_existing_tables()
        
        # í…Œì´ë¸” ìƒì„±
        loader.create_tables()
        
        # ë°ì´í„° ì ì¬
        loader.load_all_tables()
        
        # ë°ì´í„° ê²€ì¦
        verification = loader.verify_data_integrity()
        
        return verification
        
    except Exception as e:
        logger.error(f"âŒ ì ì¬ ì‹¤íŒ¨: {e}")
        raise
        
    finally:
        loader.close()


if __name__ == "__main__":
    verification_result = main()
    print(f"\nâœ… ì •ë¶€ í‘œì¤€ ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ ì™„ë£Œ!")
    print(f"ê²€ì¦ ê²°ê³¼: {json.dumps(verification_result, ensure_ascii=False, indent=2)}")