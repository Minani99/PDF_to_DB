"""
ê°œì„ ëœ JSON ë°ì´í„° ì •ê·œí™” ëª¨ë“ˆ
ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ 3NF/BCNF ì •ê·œí™” ë° ìœ ì—°í•œ ì¹´í…Œê³ ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„
"""
import json
import csv
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass, field, asdict
import hashlib
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class Department:
    """ë¶€ì²˜ ë°ì´í„° í´ë˜ìŠ¤"""
    id: int
    code: str
    name: str
    description: str = ""


@dataclass
class MainProject:
    """ì„¸ë¶€ì‚¬ì—… ë°ì´í„° í´ë˜ìŠ¤"""
    id: int
    department_id: int
    code: str
    name: str
    fiscal_year: int
    status: str = "active"


@dataclass
class SubProject:
    """ë‚´ì—­ì‚¬ì—… ë°ì´í„° í´ë˜ìŠ¤"""
    id: int
    main_project_id: int
    code: str
    name: str
    project_type: str = ""
    priority: int = 0


@dataclass
class Category:
    """ì¹´í…Œê³ ë¦¬ ë°ì´í„° í´ë˜ìŠ¤"""
    id: int
    code: str
    name: str
    parent_id: Optional[int] = None
    level: int = 1
    display_order: int = 0
    is_active: bool = True


@dataclass
class ProjectCategoryData:
    """í”„ë¡œì íŠ¸ ì¹´í…Œê³ ë¦¬ ë°ì´í„° (EAV íŒ¨í„´)"""
    id: int
    sub_project_id: int
    category_id: int
    attribute_key: str
    attribute_value: str
    data_type: str = "text"
    sequence_order: int = 0
    version: int = 1
    is_current: bool = True


class ImprovedNormalizer:
    """ê°œì„ ëœ ì •ê·œí™” í´ë˜ìŠ¤"""
    
    # ì¹´í…Œê³ ë¦¬ ì •ì˜
    CATEGORY_DEFINITIONS = {
        "overview": {"name": "ì‚¬ì—…ê°œìš”", "level": 1},
        "performance": {"name": "ì¶”ì§„ì‹¤ì ", "level": 1},
        "plan": {"name": "ì¶”ì§„ê³„íš", "level": 1},
        "budget": {"name": "ì˜ˆì‚°", "level": 2},
        "indicators": {"name": "ì„±ê³¼ì§€í‘œ", "level": 2},
        "schedule": {"name": "ì¼ì •", "level": 2},
    }
    
    def __init__(self, json_path: str, output_dir: str):
        self.json_path = Path(json_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ID ìƒì„±ê¸°
        self.id_generators = {
            "department": 1,
            "main_project": 1,
            "sub_project": 1,
            "category": 1,
            "category_data": 1,
            "overview": 1,
            "budget": 1,
            "performance": 1,
            "schedule": 1,
            "document": 1,
            "raw_page": 1,
            "audit": 1
        }
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.data = {
            "departments": [],
            "main_projects": [],
            "sub_projects": [],
            "categories": [],
            "project_category_data": [],
            "project_overviews": [],
            "budgets": [],
            "performance_indicators": [],
            "project_schedules": [],
            "document_metadata": [],
            "raw_page_data": [],
            "audit_logs": []
        }
        
        # ìºì‹œ (ì¤‘ë³µ ë°©ì§€)
        self.cache = {
            "departments": {},  # code -> id
            "main_projects": {},  # (dept_id, name) -> id
            "sub_projects": {},  # (main_id, name) -> id
            "categories": {}  # code -> id
        }
        
        # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸
        self.current_context = {
            "department_id": None,
            "main_project_id": None,
            "sub_project_id": None,
            "fiscal_year": 2024  # ê¸°ë³¸ê°’
        }
        
        self._initialize_categories()
    
    def _initialize_categories(self):
        """ì¹´í…Œê³ ë¦¬ ì´ˆê¸°í™”"""
        for code, info in self.CATEGORY_DEFINITIONS.items():
            category = Category(
                id=self._get_next_id("category"),
                code=code,
                name=info["name"],
                level=info["level"],
                display_order=len(self.data["categories"])
            )
            self.data["categories"].append(asdict(category))
            self.cache["categories"][code] = category.id
    
    def _get_next_id(self, entity_type: str) -> int:
        """ë‹¤ìŒ ID ìƒì„±"""
        current_id = self.id_generators[entity_type]
        self.id_generators[entity_type] += 1
        return current_id
    
    def _extract_fiscal_year(self, text: str) -> int:
        """íšŒê³„ì—°ë„ ì¶”ì¶œ"""
        match = re.search(r'20\d{2}', text)
        if match:
            return int(match.group())
        return self.current_context["fiscal_year"]
    
    def _extract_department(self, text: str) -> Tuple[str, str]:
        """ë¶€ì²˜ ì •ë³´ ì¶”ì¶œ"""
        # ë¶€ì²˜ íŒ¨í„´ ë§¤ì¹­
        dept_patterns = [
            (r'ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€', 'MSIT', 'ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€'),
            (r'ë³´ê±´ë³µì§€ë¶€', 'MOHW', 'ë³´ê±´ë³µì§€ë¶€'),
            (r'ì‚°ì—…í†µìƒìì›ë¶€', 'MOTIE', 'ì‚°ì—…í†µìƒìì›ë¶€'),
            (r'êµìœ¡ë¶€', 'MOE', 'êµìœ¡ë¶€'),
        ]
        
        for pattern, code, name in dept_patterns:
            if re.search(pattern, text):
                return code, name
        
        return 'UNKNOWN', 'ë¯¸ë¶„ë¥˜'
    
    def _create_or_get_department(self, code: str, name: str) -> int:
        """ë¶€ì²˜ ìƒì„± ë˜ëŠ” ì¡°íšŒ"""
        if code in self.cache["departments"]:
            return self.cache["departments"][code]
        
        dept = Department(
            id=self._get_next_id("department"),
            code=code,
            name=name,
            description=f"{name} ê´€ë ¨ ì‚¬ì—…"
        )
        
        self.data["departments"].append(asdict(dept))
        self.cache["departments"][code] = dept.id
        
        self._add_audit_log("departments", dept.id, "INSERT", None, asdict(dept))
        
        return dept.id
    
    def _create_or_get_main_project(self, dept_id: int, name: str, fiscal_year: int) -> int:
        """ì„¸ë¶€ì‚¬ì—… ìƒì„± ë˜ëŠ” ì¡°íšŒ"""
        cache_key = (dept_id, name)
        if cache_key in self.cache["main_projects"]:
            return self.cache["main_projects"][cache_key]
        
        # ì‚¬ì—… ì½”ë“œ ìƒì„±
        code = f"MAIN-{fiscal_year}-{self.id_generators['main_project']:03d}"
        
        project = MainProject(
            id=self._get_next_id("main_project"),
            department_id=dept_id,
            code=code,
            name=name,
            fiscal_year=fiscal_year
        )
        
        self.data["main_projects"].append(asdict(project))
        self.cache["main_projects"][cache_key] = project.id
        
        self._add_audit_log("main_projects", project.id, "INSERT", None, asdict(project))
        
        return project.id
    
    def _create_or_get_sub_project(self, main_id: int, name: str, project_type: str = "") -> int:
        """ë‚´ì—­ì‚¬ì—… ìƒì„± ë˜ëŠ” ì¡°íšŒ"""
        cache_key = (main_id, name)
        if cache_key in self.cache["sub_projects"]:
            return self.cache["sub_projects"][cache_key]
        
        # ì‚¬ì—… ì½”ë“œ ìƒì„±
        code = f"SUB-{self.current_context['fiscal_year']}-{self.id_generators['sub_project']:03d}"
        
        project = SubProject(
            id=self._get_next_id("sub_project"),
            main_project_id=main_id,
            code=code,
            name=name,
            project_type=project_type
        )
        
        self.data["sub_projects"].append(asdict(project))
        self.cache["sub_projects"][cache_key] = project.id
        
        self._add_audit_log("sub_projects", project.id, "INSERT", None, asdict(project))
        
        return project.id
    
    def _add_category_data(self, sub_project_id: int, category_code: str, 
                          key: str, value: str, data_type: str = "text"):
        """ì¹´í…Œê³ ë¦¬ ë°ì´í„° ì¶”ê°€ (EAV íŒ¨í„´)"""
        if not value or not value.strip():
            return
        
        category_id = self.cache["categories"].get(category_code)
        if not category_id:
            logger.warning(f"Category not found: {category_code}")
            return
        
        data = ProjectCategoryData(
            id=self._get_next_id("category_data"),
            sub_project_id=sub_project_id,
            category_id=category_id,
            attribute_key=key,
            attribute_value=value.strip(),
            data_type=data_type,
            sequence_order=len([d for d in self.data["project_category_data"] 
                               if d["sub_project_id"] == sub_project_id])
        )
        
        self.data["project_category_data"].append(asdict(data))
    
    def _process_overview_data(self, sub_project_id: int, rows: List[List[str]]):
        """ì‚¬ì—…ê°œìš” ë°ì´í„° ì²˜ë¦¬"""
        overview_data = {
            "id": self._get_next_id("overview"),
            "sub_project_id": sub_project_id,
            "managing_org": "",
            "supervising_org": "",
            "research_period": "",
            "total_budget": None,
            "objectives": "",
            "content": "",
            "representative_field": ""
        }
        
        for row in rows:
            if len(row) < 2:
                continue
            
            key = str(row[0]).strip()
            value = str(row[1]).strip() if len(row) > 1 else ""
            
            # êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
            if 'ì£¼ê´€ê¸°ê´€' in key:
                overview_data["managing_org"] = value
            elif 'ê´€ë¦¬ê¸°ê´€' in key or 'ì „ë¬¸ê¸°ê´€' in key:
                overview_data["supervising_org"] = value
            elif 'ì—°êµ¬ê¸°ê°„' in key or 'ì´ ì—°êµ¬ê¸°ê°„' in key:
                overview_data["research_period"] = value
            elif 'ì‚¬ì—…ëª©í‘œ' in key:
                overview_data["objectives"] = value
            elif 'ì‚¬ì—…ë‚´ìš©' in key:
                overview_data["content"] = value
            elif 'ëŒ€í‘œë¶„ì•¼' in key:
                overview_data["representative_field"] = value
            elif 'ì´ ì—°êµ¬ë¹„' in key or 'ì´ì‚¬ì—…ë¹„' in key:
                # ê¸ˆì•¡ íŒŒì‹±
                budget_match = re.search(r'[\d,]+', value)
                if budget_match:
                    try:
                        overview_data["total_budget"] = float(
                            budget_match.group().replace(',', '')
                        )
                    except ValueError:
                        pass
            
            # EAV íŒ¨í„´ìœ¼ë¡œë„ ì €ì¥ (ìœ ì—°ì„±)
            self._add_category_data(sub_project_id, "overview", key, value)
        
        self.data["project_overviews"].append(overview_data)
    
    def _process_budget_data(self, sub_project_id: int, rows: List[List[str]]):
        """ì˜ˆì‚° ë°ì´í„° ì²˜ë¦¬"""
        headers = rows[0] if rows else []
        
        for row in rows[1:]:
            if len(row) < 2:
                continue
            
            year = self._extract_fiscal_year(str(row[0]))
            if not year:
                continue
            
            for i, cell in enumerate(row[1:], 1):
                if i >= len(headers):
                    break
                
                budget_type = str(headers[i]).strip()
                if not budget_type or budget_type in ['êµ¬ë¶„', 'ë…„ë„']:
                    continue
                
                try:
                    amount = float(str(cell).replace(',', '').replace(' ', ''))
                    
                    budget_data = {
                        "id": self._get_next_id("budget"),
                        "sub_project_id": sub_project_id,
                        "fiscal_year": year,
                        "budget_type": budget_type,
                        "planned_amount": amount,
                        "executed_amount": None,
                        "execution_rate": None,
                        "currency": "KRW",
                        "remarks": ""
                    }
                    
                    self.data["budgets"].append(budget_data)
                    
                    # EAV íŒ¨í„´ìœ¼ë¡œë„ ì €ì¥
                    self._add_category_data(
                        sub_project_id, "budget",
                        f"{year}_{budget_type}", str(amount), "number"
                    )
                except (ValueError, TypeError):
                    continue
    
    def _process_performance_data(self, sub_project_id: int, rows: List[List[str]]):
        """ì„±ê³¼ ì§€í‘œ ë°ì´í„° ì²˜ë¦¬"""
        for row in rows[1:]:
            if len(row) < 2:
                continue
            
            indicator_name = str(row[0]).strip()
            if not indicator_name or 'ì„±ê³¼ì§€í‘œ' in indicator_name:
                continue
            
            # ì§€í‘œ íƒ€ì… ì¶”ë¡ 
            indicator_type = self._infer_indicator_type(indicator_name)
            
            target_value = None
            unit = ""
            
            if len(row) > 1:
                value_str = str(row[1]).strip()
                # ìˆ«ìì™€ ë‹¨ìœ„ ë¶„ë¦¬
                match = re.match(r'([\d,.]+)\s*(.+)?', value_str)
                if match:
                    try:
                        target_value = float(match.group(1).replace(',', ''))
                        unit = match.group(2) or "" if match.lastindex > 1 else ""
                    except ValueError:
                        pass
            
            if len(row) > 2:
                unit = str(row[2]).strip() or unit
            
            performance_data = {
                "id": self._get_next_id("performance"),
                "sub_project_id": sub_project_id,
                "indicator_type": indicator_type,
                "indicator_name": indicator_name,
                "target_value": target_value,
                "achieved_value": None,
                "achievement_rate": None,
                "unit": unit,
                "measurement_year": self.current_context["fiscal_year"]
            }
            
            self.data["performance_indicators"].append(performance_data)
            
            # EAV íŒ¨í„´ìœ¼ë¡œë„ ì €ì¥
            self._add_category_data(
                sub_project_id, "indicators",
                indicator_name, f"{target_value} {unit}" if target_value else ""
            )
    
    def _infer_indicator_type(self, indicator_name: str) -> str:
        """ì§€í‘œ íƒ€ì… ì¶”ë¡ """
        type_patterns = {
            "íŠ¹í—ˆ": ["íŠ¹í—ˆ", "ì¶œì›", "ë“±ë¡"],
            "ë…¼ë¬¸": ["ë…¼ë¬¸", "SCI", "SCIE", "í•™ìˆ ì§€"],
            "ê¸°ìˆ ì´ì „": ["ê¸°ìˆ ì´ì „", "ê¸°ìˆ ë£Œ", "ë¼ì´ì„¼ìŠ¤"],
            "ì¸ë ¥ì–‘ì„±": ["ë°•ì‚¬", "ì„ì‚¬", "ì¸ë ¥", "ì–‘ì„±"],
            "ê¸°íƒ€": []
        }
        
        lower_name = indicator_name.lower()
        for type_name, patterns in type_patterns.items():
            if any(pattern.lower() in lower_name for pattern in patterns):
                return type_name
        
        return "ê¸°íƒ€"
    
    def _process_schedule_data(self, sub_project_id: int, rows: List[List[str]]):
        """ì¼ì • ë°ì´í„° ì²˜ë¦¬"""
        for row in rows[1:]:
            if len(row) < 2:
                continue
            
            task_name = str(row[0]).strip()
            if not task_name or 'ì¶”ì§„ê³„íš' in task_name:
                continue
            
            schedule_text = str(row[1]).strip() if len(row) > 1 else ""
            
            # ë¶„ê¸° ì •ë³´ ì¶”ì¶œ
            phase = self._extract_phase(schedule_text)
            
            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            dates = self._extract_dates(schedule_text)
            
            schedule_data = {
                "id": self._get_next_id("schedule"),
                "sub_project_id": sub_project_id,
                "phase": phase,
                "task_name": task_name,
                "start_date": dates[0] if dates else None,
                "end_date": dates[1] if len(dates) > 1 else None,
                "status": "planned",
                "description": schedule_text
            }
            
            self.data["project_schedules"].append(schedule_data)
            
            # EAV íŒ¨í„´ìœ¼ë¡œë„ ì €ì¥
            self._add_category_data(
                sub_project_id, "schedule",
                task_name, schedule_text
            )
    
    def _extract_phase(self, text: str) -> str:
        """ë¶„ê¸° ì •ë³´ ì¶”ì¶œ"""
        phase_match = re.search(r'(\d)/4\s*ë¶„ê¸°', text)
        if phase_match:
            return f"{phase_match.group(1)}/4ë¶„ê¸°"
        
        month_match = re.search(r'(\d{1,2})ì›”', text)
        if month_match:
            month = int(month_match.group(1))
            if month <= 3:
                return "1/4ë¶„ê¸°"
            elif month <= 6:
                return "2/4ë¶„ê¸°"
            elif month <= 9:
                return "3/4ë¶„ê¸°"
            else:
                return "4/4ë¶„ê¸°"
        
        return "ì—°ì¤‘"
    
    def _extract_dates(self, text: str) -> List[str]:
        """ë‚ ì§œ ì •ë³´ ì¶”ì¶œ"""
        dates = []
        
        # YYYY.MM ë˜ëŠ” YYYY-MM íŒ¨í„´
        date_pattern = r'20\d{2}[-./]\d{1,2}'
        matches = re.findall(date_pattern, text)
        
        for match in matches[:2]:  # ìµœëŒ€ 2ê°œ (ì‹œì‘, ì¢…ë£Œ)
            # ë‚ ì§œ í˜•ì‹ ì •ê·œí™”
            normalized = match.replace('.', '-').replace('/', '-')
            if len(normalized.split('-')[1]) == 1:
                parts = normalized.split('-')
                normalized = f"{parts[0]}-{parts[1]:0>2}"
            dates.append(f"{normalized}-01")  # ì¼ìëŠ” 1ì¼ë¡œ ê¸°ë³¸ ì„¤ì •
        
        return dates
    
    def _add_audit_log(self, table_name: str, record_id: int, 
                      action: str, old_value: Any, new_value: Any):
        """ê°ì‚¬ ë¡œê·¸ ì¶”ê°€"""
        audit = {
            "id": self._get_next_id("audit"),
            "table_name": table_name,
            "record_id": record_id,
            "action": action,
            "old_value": json.dumps(old_value, ensure_ascii=False) if old_value else None,
            "new_value": json.dumps(new_value, ensure_ascii=False) if new_value else None,
            "changed_by": "system",
            "changed_at": datetime.now().isoformat()
        }
        
        self.data["audit_logs"].append(audit)
    
    def _process_page(self, page: Dict[str, Any], page_number: int, document_id: int):
        """í˜ì´ì§€ ì²˜ë¦¬"""
        # ì›ë³¸ ë°ì´í„° ì €ì¥
        raw_data = {
            "id": self._get_next_id("raw_page"),
            "document_id": document_id,
            "page_number": page_number,
            "raw_text": page.get('full_text', ''),
            "extracted_tables": json.dumps(page.get('tables', []), ensure_ascii=False),
            "processing_notes": ""
        }
        self.data["raw_page_data"].append(raw_data)
        
        # ë¶€ì²˜ ì •ë³´ ì¶”ì¶œ
        full_text = page.get('full_text', '')
        dept_code, dept_name = self._extract_department(full_text)
        dept_id = self._create_or_get_department(dept_code, dept_name)
        self.current_context["department_id"] = dept_id
        
        # í…Œì´ë¸” ì²˜ë¦¬
        for table in page.get('tables', []):
            self._process_table(table, page_number, full_text)
    
    def _process_table(self, table: Dict[str, Any], page_number: int, full_text: str):
        """í…Œì´ë¸” ì²˜ë¦¬"""
        rows = table.get('data', [])
        if not rows:
            return
        
        headers = rows[0] if rows else []
        table_type = self._detect_table_type(headers, rows, full_text)
        
        if table_type == "project_header":
            self._process_project_header(rows, page_number)
        elif table_type == "budget" and self.current_context["sub_project_id"]:
            self._process_budget_data(self.current_context["sub_project_id"], rows)
        elif table_type == "performance" and self.current_context["sub_project_id"]:
            self._process_performance_data(self.current_context["sub_project_id"], rows)
        elif table_type == "schedule" and self.current_context["sub_project_id"]:
            self._process_schedule_data(self.current_context["sub_project_id"], rows)
    
    def _detect_table_type(self, headers: List[str], rows: List[List[str]], 
                          full_text: str) -> str:
        """í…Œì´ë¸” íƒ€ì… ê°ì§€"""
        headers_str = ' '.join(str(h) for h in headers).lower()
        
        # í”„ë¡œì íŠ¸ í—¤ë” í…Œì´ë¸”
        if any(kw in headers_str for kw in ['ì„¸ë¶€ì‚¬ì—…ëª…', 'ë‚´ì—­ì‚¬ì—…ëª…', 'ì‚¬ì—…ê°œìš”']):
            return "project_header"
        
        # ì¹´í…Œê³ ë¦¬ë³„ í…Œì´ë¸”
        if 'ì˜ˆì‚°' in headers_str or 'ì‚¬ì—…ë¹„' in headers_str or 'êµ­ê³ ' in headers_str:
            return "budget"
        elif 'ì„±ê³¼' in headers_str or 'ì§€í‘œ' in headers_str or 'íŠ¹í—ˆ' in headers_str:
            return "performance"
        elif 'ì¼ì •' in headers_str or 'ì¶”ì§„ê³„íš' in headers_str or 'ë¶„ê¸°' in headers_str:
            return "schedule"
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ë¡ 
        if 'ì¶”ì§„ì‹¤ì ' in full_text:
            return "performance"
        elif 'ì¶”ì§„ê³„íš' in full_text:
            return "schedule"
        
        return "unknown"
    
    def _process_project_header(self, rows: List[List[str]], page_number: int):
        """í”„ë¡œì íŠ¸ í—¤ë” ì²˜ë¦¬"""
        main_project_name = ""
        sub_project_name = ""
        project_type = ""
        
        for row in rows:
            if len(row) < 2:
                continue
            
            key = str(row[0]).strip()
            value = str(row[1]).strip() if len(row) > 1 else ""
            
            if 'ì„¸ë¶€ì‚¬ì—…ëª…' in key:
                main_project_name = value
            elif 'ë‚´ì—­ì‚¬ì—…ëª…' in key:
                sub_project_name = value
            elif 'ì‚¬ì—…ì„±ê²©' in key:
                project_type = value
        
        # ì„¸ë¶€ì‚¬ì—… ì²˜ë¦¬
        if main_project_name and self.current_context["department_id"]:
            fiscal_year = self._extract_fiscal_year(main_project_name)
            self.current_context["fiscal_year"] = fiscal_year
            
            main_id = self._create_or_get_main_project(
                self.current_context["department_id"],
                main_project_name,
                fiscal_year
            )
            self.current_context["main_project_id"] = main_id
        
        # ë‚´ì—­ì‚¬ì—… ì²˜ë¦¬
        if sub_project_name and self.current_context["main_project_id"]:
            sub_id = self._create_or_get_sub_project(
                self.current_context["main_project_id"],
                sub_project_name,
                project_type
            )
            self.current_context["sub_project_id"] = sub_id
            
            # ì‚¬ì—…ê°œìš” ë°ì´í„° ì²˜ë¦¬
            self._process_overview_data(sub_id, rows)
    
    def normalize(self) -> bool:
        """ì •ê·œí™” ì‹¤í–‰"""
        try:
            logger.info(f"ì •ê·œí™” ì‹œì‘: {self.json_path}")
            
            # JSON ë¡œë“œ
            with open(self.json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            
            # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì €ì¥
            document_id = self._get_next_id("document")
            self.data["document_metadata"].append({
                "id": document_id,
                "file_name": self.json_path.stem,
                "file_path": str(self.json_path),
                "file_size": self.json_path.stat().st_size,
                "page_count": len(json_data.get('pages', [])),
                "extraction_date": datetime.now().isoformat(),
                "processing_status": "processing",
                "error_message": None
            })
            
            # í˜ì´ì§€ë³„ ì²˜ë¦¬
            for page_idx, page in enumerate(json_data.get('pages', []), 1):
                self._process_page(page, page_idx, document_id)
            
            # ë¬¸ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸
            for doc in self.data["document_metadata"]:
                if doc["id"] == document_id:
                    doc["processing_status"] = "completed"
                    break
            
            # CSV ì €ì¥
            self._save_to_csv()
            
            # í†µê³„ ì¶œë ¥
            self._print_statistics()
            
            logger.info("ì •ê·œí™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ì •ê·œí™” ì‹¤íŒ¨: {e}")
            
            # ì—ëŸ¬ ìƒíƒœ ì—…ë°ì´íŠ¸
            for doc in self.data["document_metadata"]:
                if doc["id"] == document_id:
                    doc["processing_status"] = "failed"
                    doc["error_message"] = str(e)
                    break
            
            import traceback
            traceback.print_exc()
            return False
    
    def _save_to_csv(self):
        """CSV íŒŒì¼ë¡œ ì €ì¥"""
        for table_name, records in self.data.items():
            if not records:
                continue
            
            csv_path = self.output_dir / f"{table_name}.csv"
            
            with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=records[0].keys())
                writer.writeheader()
                writer.writerows(records)
            
            logger.info(f"âœ… {table_name}.csv ì €ì¥ ì™„ë£Œ ({len(records)}ê±´)")
    
    def _print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ì •ê·œí™” ì™„ë£Œ í†µê³„")
        print("="*80)
        
        stats = {
            "ğŸ“‚ ë¶€ì²˜": len(self.data["departments"]),
            "ğŸ“‹ ì„¸ë¶€ì‚¬ì—…": len(self.data["main_projects"]),
            "ğŸ“ ë‚´ì—­ì‚¬ì—…": len(self.data["sub_projects"]),
            "ğŸ·ï¸ ì¹´í…Œê³ ë¦¬": len(self.data["categories"]),
            "ğŸ“Š ì¹´í…Œê³ ë¦¬ ë°ì´í„°": len(self.data["project_category_data"]),
            "ğŸ“„ ì‚¬ì—…ê°œìš”": len(self.data["project_overviews"]),
            "ğŸ’° ì˜ˆì‚°": len(self.data["budgets"]),
            "ğŸ“ˆ ì„±ê³¼ì§€í‘œ": len(self.data["performance_indicators"]),
            "ğŸ“… ì¼ì •": len(self.data["project_schedules"]),
            "ğŸ“‘ ë¬¸ì„œ": len(self.data["document_metadata"]),
            "ğŸ“ƒ í˜ì´ì§€": len(self.data["raw_page_data"]),
            "ğŸ“ ê°ì‚¬ë¡œê·¸": len(self.data["audit_logs"])
        }
        
        for label, count in stats.items():
            print(f"{label}: {count}ê±´")
        
        print("="*80 + "\n")


def normalize_json_improved(json_path: str, output_dir: str) -> bool:
    """ê°œì„ ëœ ì •ê·œí™” ì‹¤í–‰ í•¨ìˆ˜"""
    normalizer = ImprovedNormalizer(json_path, output_dir)
    return normalizer.normalize()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    json_file = "output/extracted_data.json"
    output_folder = "normalized_output_improved"
    
    if Path(json_file).exists():
        success = normalize_json_improved(json_file, output_folder)
        if success:
            print("âœ… ì •ê·œí™” ì„±ê³µ!")
        else:
            print("âŒ ì •ê·œí™” ì‹¤íŒ¨!")
    else:
        print(f"âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")